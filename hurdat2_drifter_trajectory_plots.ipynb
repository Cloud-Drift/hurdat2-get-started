{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting HURDAT2 Storms Alongside Drifter Tracks\n",
    "\n",
    "In this notebook we will walk through how we can use the [`clouddrift`](https://github.com/Cloud-Drift/clouddrift) library to plot NOAA GDP drifter tracks colored by sea surface temperature, alongside storm tracks from the HURDAT2 dataset, with both datasets directly available from the library. HURDAT2 is a dataset that contains storm track data (including pressure, wind speed, etc...) for the time period 1852 to 2022, both from the North Pacific and North Atlantic ocean basins. The HURDAT2 dataset is originally available from [NOAA AOML](https://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html), and such is the [NOAA GDP dataset](https://www.aoml.noaa.gov/phod/gdp/index.php).\n",
    "\n",
    "This notebook proceeds in steps by:\n",
    " 1. Access and open the necessary datasets,\n",
    " 2. Subset these datasets by selecting their data for a given year and region,\n",
    " 3. Generate an animation showing as a function of time the selected data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful library imports\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import clouddrift as cd\n",
    "from clouddrift.ragged import unpack\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# plotting and mapping imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset imports\n",
    "\n",
    "We access and open as an xarray dataset a ragged array version of the [six-hourly NOAA Global Drifter Program dataset](https://www.aoml.noaa.gov/phod/gdp/interpolated/data/all.php) which is hosted as an experiment in an AWS S3 bucket. Please consult the webpage of the dataset to investigate alternative ways of accessing these data. Below we also provide a couple of alternative ways of accessing these data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset URL on the AWS S3 bucket:\n",
    "url = \"https://noaa-oar-hourly-gdp-pds.s3.amazonaws.com/experimental/gdp6h_ragged_sep23.zarr\"\n",
    "drifter_ds = xr.open_dataset(url, decode_times=False, engine=\"zarr\")\n",
    "# re-assign and rename the ID variable to follow clouddrift conventions for ragged array datasets:\n",
    "drifter_ds = drifter_ds.rename_vars({\"ID\": \"id\"}).assign_coords({\"id\": drifter_ds.ID}).drop_vars([\"ids\"])\n",
    "\n",
    "# alternatively, access the ragged array 6-hourly dataset from the AOML website via the clouddrift API with the following command:\n",
    "# drifter_ds = cd.datasets.gdp6h()\n",
    "\n",
    "# alternatively, access the individual netcdf files from the AOML FTP server and aggegrate locally these data into a ragged array dataset via the cloudrift API with the following command:\n",
    "# drifter_ds = cd.adapters.gdp6h.to_raggedarray().to_xarray()\n",
    "\n",
    "drifter_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we access the HURDAT2 dataset directly using the clouddrift API. The command below looks for the dataset locally and if it is not found the original data are downloaded and aggregated into a ragged array dataset which is then opened as an xarray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_ds = cd.datasets.hurdat2(decode_times=True)\n",
    "storm_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Subsample the datasets\n",
    "\n",
    "Next we select specific subsets of the opened datasets. For this, we use the clouddrift `subset` function provided through the `ragged` module which contains helpful utility functions for working with ragged array data structures. Here we choose to subset storms whose track lied within the Atlantic Ocean near the east coast of North America and was observed between August and October of 2020 (feel free to change any of this selection when running this notebook).  The `subset` function requires to define a criteria as a dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a time range\n",
    "year = 2020\n",
    "start_dt, end_dt = datetime(year, 8, 1), datetime(year, 10, 1)\n",
    "# define the criteria for the drifter and storm datasets; please note that the times are encoding differently in the two datasets and as such we need to specify the time range differently for each criteria.\n",
    "\n",
    "drifter_criteria = dict(\n",
    "    lat=(10, 50),\n",
    "    lon=(-80, -20), \n",
    "    time=(\n",
    "        start_dt.timestamp(),\n",
    "        end_dt.timestamp()\n",
    "    )\n",
    ")\n",
    "\n",
    "storm_criteria = criteria = dict(\n",
    "    lat=(10, 50),\n",
    "    lon=(-80, -20), \n",
    "    time=(\n",
    "        np.datetime64(int(start_dt.timestamp()), \"s\"),\n",
    "        np.datetime64(int(end_dt.timestamp()), \"s\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `subset` function and apply the criteria to both datasets. The `subset` function requires to provide the name of the *row* dimension for the ragged array datasets (see the [clouddrift documentation](https://clouddrift.org)), which is `traj` in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_storms = cd.ragged.subset(storm_ds, storm_criteria, row_dim_name=\"traj\")\n",
    "matching_storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_drifters = cd.ragged.subset(drifter_ds, drifter_criteria, row_dim_name=\"traj\")\n",
    "matching_drifters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plotting and Animation.\n",
    "\n",
    "Subsetting the datasets above, you should have found 14 storms and 248 drifters. We will now proceed to create a map and some animation to visualize the selected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blank figure with the desired size and resolution\n",
    "DPI = 384\n",
    "fig = plt.figure(figsize=(7.75, 4.75), dpi=DPI)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mollweide())\n",
    "ax.set_extent([-100, 0, 0, 80], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels=True)\n",
    "# why can't we plot let's say all the drifter trajectories?\n",
    "# line1 = cd.plotting.plot_ragged(ax,\n",
    "#                                 matching_drifters[\"lon\"], \n",
    "#                                 matching_drifters[\"lat\"], \n",
    "#                                 rowsize=matching_drifters[\"rowsize\"],\n",
    "#                                 colors=np.arange(len(matching_drifters[\"rowsize\"])),\n",
    "#                                 transform=ccrs.PlateCarree(),\n",
    "#                                 cmap=\"Blues\",)\n",
    "datetime_label = ax.text(-115, 40, start_dt.strftime('%Y-%m-%d %H:%M:%S'), \n",
    "    fontsize=10, \n",
    "    color=\"red\", \n",
    "    transform=ccrs.PlateCarree(), \n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"none\")\n",
    ")\n",
    "ax.set_title(\"Hurricane Season\"+str(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were going to iterate over both, the selected storms and the selected drifters. For each of the trajectories, we plot their starting point and store some data to be utilized for generating the animation.\n",
    "\n",
    "Lets unpack the data variables from a ragged array (1-d array composed of each rows data variable segment) into a list of row data variable segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indices for the number of storms and the number of drifters selected\n",
    "storm_indices = np.arange(0,len(matching_storms[\"id\"]))\n",
    "drifter_indices = np.arange(0,len(matching_drifters[\"id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the animation we need to work on the data of each individual storm and each individual drifter. Because these datasets are organized as ragged arrays, we use the clouddrift `unpack` function to generate lists of data. The `unpack` function takes as arguments a ragged array input and a *rowsize* variable that indicates the size of each row of the ragged array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the lat and lon data for the storms\n",
    "storm_lons = unpack(matching_storms.lon, matching_storms.rowsize)\n",
    "storm_lats = unpack(matching_storms.lat, matching_storms.rowsize)\n",
    "\n",
    "# unpack the lat, lon, and sst data for the drifters\n",
    "drifter_lons = unpack(matching_drifters.lon, matching_drifters[\"rowsize\"])\n",
    "drifter_lats = unpack(matching_drifters.lat, matching_drifters[\"rowsize\"])\n",
    "drifter_temps = unpack(matching_drifters.temp, matching_drifters[\"rowsize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the unpacked rows and plot the initial starting point of the storm and drifter trajectories (we also do some setup with setting up indices to make searching easier later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_lines = list()\n",
    "drifter_lines = list()\n",
    "\n",
    "for storm_idx in storm_indices:\n",
    "    selected_lon, selected_lat = storm_lons[storm_idx], storm_lats[storm_idx]\n",
    "    selected_lon, selected_lat = selected_lon.set_xindex(\"time\"), selected_lat.set_xindex(\"time\")\n",
    "    line = ax.plot(selected_lon[0], selected_lat[0],\n",
    "        linestyle=\"-\", linewidth=3,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "    storm_lines.append((selected_lon, selected_lat, line[0]))\n",
    "\n",
    "for drifter_idx in drifter_indices:\n",
    "    selected_lon, selected_lat, selected_temp = drifter_lons[drifter_idx], drifter_lats[drifter_idx], drifter_temps[drifter_idx]\n",
    "    selected_lon, selected_lat, selected_temp = (selected_lon.set_xindex(\"time\"), selected_lat.set_xindex(\"time\"), selected_temp.set_xindex(\"time\"))\n",
    "    line = ax.plot(selected_lon[0], selected_lat[0],\n",
    "        linestyle=\"-\", linewidth=1,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "    drifter_lines.append((selected_lon, selected_lat, selected_temp, line[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now find the upper and lower bounds for the temperature values being plotted. We'll use this to create a colormap to color the drifter trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the min and max temperatire for the colorscale/colormap\n",
    "min_t = np.nanmin([np.nanmin(temp) for (_, _, temp, _) in drifter_lines])\n",
    "max_t = np.nanmax([np.nanmax(temp) for (_, _, temp, _) in drifter_lines])\n",
    "\n",
    "cmap = plt.get_cmap(\"inferno\")\n",
    "norm = colors.Normalize(vmin=min_t, vmax=max_t)\n",
    "\n",
    "print((min_t, max_t, cmap(norm(80))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the legend for the colorbar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size=\"3%\", pad=0.75, axes_class=plt.Axes)\n",
    "fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax, label=\"temperature (K)\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the start and end date we've used for the data criteria and generate an range of values that each map uniquely to a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 500\n",
    "daterange = pd.date_range(start_dt, end_dt, frame_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate each frame by selecting the date associated to it which we utilize to update each trajectory with new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_frames = list()\n",
    "drifter_frames = list()\n",
    "frames = dict()\n",
    "tail_len = 50\n",
    "\n",
    "for idx, dt in enumerate(daterange):\n",
    "    if ((idx+1) % 100 == 0):\n",
    "        print(f\"generating index: {idx}\")\n",
    "\n",
    "    storm_updates = list()\n",
    "    for s_lon, s_lat, s_line in storm_lines:\n",
    "        sel_d_lon = s_lon.sel(time=slice(start_dt, dt))\n",
    "        sel_d_lat = s_lat.sel(time=slice(start_dt, dt))\n",
    "        storm_updates.append((sel_d_lon, sel_d_lat, s_line))\n",
    "\n",
    "    drifter_updates = list()\n",
    "    for d_lon, d_lat, d_temp, d_line, in drifter_lines:\n",
    "        sel_d_lon = d_lon.sel(time=slice(start_dt.timestamp(), dt.timestamp()))\n",
    "        sel_d_lat = d_lat.sel(time=slice(start_dt.timestamp(), dt.timestamp()))\n",
    "        sel_d_temp = d_temp.sel(time=slice(start_dt.timestamp(), dt.timestamp()))\n",
    "        sel_d_lon = sel_d_lon.tail(obs=tail_len)\n",
    "        sel_d_lat = sel_d_lat.tail(obs=tail_len)\n",
    "        sel_d_temp = sel_d_temp.tail(obs=tail_len)\n",
    "        drifter_updates.append((sel_d_lon, sel_d_lat, sel_d_temp, d_line))\n",
    "\n",
    "    frames[dt] = dict(drifter_updates=drifter_updates, storm_updates=storm_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an update function that, using the frame index, selects the frame and updates each trajectories longitude and latitude (and also temperature for the case of the drifters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_dates = sorted(frames.keys())\n",
    "\n",
    "def update(frame_idx):\n",
    "    frame_dt = sorted_dates[frame_idx]\n",
    "    frame = frames[frame_dt]\n",
    "    drifter_updates = frame[\"drifter_updates\"]\n",
    "    storm_updates = frame[\"storm_updates\"]\n",
    "\n",
    "    datetime_label.set_text(frame_dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    updated_lines = list()\n",
    "    for x_update, y_update, line in storm_updates:\n",
    "        line.set_xdata(x_update)\n",
    "        line.set_ydata(y_update)\n",
    "        updated_lines.append(line)\n",
    "\n",
    "    for x_update, y_update, temps, line in drifter_updates:\n",
    "        line.set_xdata(x_update)\n",
    "        line.set_ydata(y_update)\n",
    "        if len(temps.data) > 0:\n",
    "            line.set_color(cmap(norm(np.nanmean(temps))))\n",
    "        updated_lines.append(line)\n",
    "    return updated_lines\n",
    "\n",
    "ani = animation.FuncAnimation(fig=fig, func=update, frames=frame_count, interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's generate the animation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # bad practice and should never be used but helps us keep the output clean and should only ever be used in experimental/sample code.\n",
    "\n",
    "ani.save(\"storm_drifters.gif\", dpi=DPI, progress_callback=lambda i, n: print(f'Saving frame {i}/{n}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your working directory should now contains the `storm_drifters.gif` file. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
