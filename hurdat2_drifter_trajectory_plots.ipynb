{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurdat2, Plotting Storm Alongside Drifter Tracks With Average Temperature\n",
    "In the following example we will walk through how we can leverage the `clouddrift` library to plot drifter tracks colored by temperature recorded alongside hurricane storm tracks obtained from the HURDAT2 dataset. Simply put, the HURDAT2 dataset is a dataset that contains storm track data (including other measurements such as pressure, wind speed, etc...) for storms recorded from 1852 - 2022 across both the Pacific and Atlantic Ocean.\n",
    "\n",
    "Lets proceed with loading in the datasets were interested in taking a look at.\n",
    "\n",
    "We'll start with loading the drifter dataset. This will download and generate an aggregate version of the drifters dataset. Note this process may take some time ~15m and is only performed once unless the force flag is flipped to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clouddrift\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "fp = \"aggregate_gdp6h_local.nc\"\n",
    "force = False\n",
    "\n",
    "if not os.path.exists(fp) or force:\n",
    "    clouddrift.adapters.gdp6h.to_raggedarray(n_random_id=10_000).to_netcdf(fp)\n",
    "    drifter_ds = xr.load_dataset(fp, decode_times=True)\n",
    "else:\n",
    "    drifter_ds = xr.load_dataset(fp, decode_times=True)\n",
    "drifter_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now also load in the HURDAT2 storm dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_ds = clouddrift.datasets.hurdat2(decode_times=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say that we'd like to select a specific subset of this dataset; we can leverage the `subset` utility function provided through the `ragged` module which contains a library of helpful utility functions for working with the `RaggedArray` data structure.\n",
    "\n",
    "As an example say you wanted a subset of the dataset for storms whose track lied within the Atlantic Ocean near the east coast of North America and was observed between August and October of 2020. You can leverage the `subset` function to help you achieve this by first defining the criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some helpful libraries\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Here the datasets variables are mapped to an (inclusive start and end) range\n",
    "start_dt, end_dt = datetime(2020, 8, 1), datetime(2020, 10, 1)\n",
    "criteria = dict(\n",
    "    lat=(10, 50),\n",
    "    lon=(-80, -20), \n",
    "    time=(\n",
    "        np.datetime64(int(start_dt.timestamp()), \"s\"),\n",
    "        np.datetime64(int(end_dt.timestamp()), \"s\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the `subset` function and apply the criteria to both datasets. Here we need to provide the row dimensions alias which is `traj` in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_storms = clouddrift.ragged.subset(storm_ds, criteria, row_dim_name=\"traj\")\n",
    "matching_storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_drifters = clouddrift.ragged.subset(drifter_ds, criteria, row_dim_name=\"traj\")\n",
    "matching_drifters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create our base plot where we will plot the drifter and storm trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs  # cartopy for projecting our dataset onto different map projections\n",
    "import matplotlib.pyplot as plt # is an standard plotting library\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "DPI = 384\n",
    "fig = plt.figure(figsize=(7.75, 4.75), dpi=DPI)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mollweide())\n",
    "ax.set_extent([-100, 0, 0, 80], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels=True)\n",
    "datetime_label = ax.text(-115, 40, start_dt.strftime('%Y-%m-%d %H:%M:%S'), \n",
    "    fontsize=10, \n",
    "    color=\"red\", \n",
    "    transform=ccrs.PlateCarree(), \n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"none\")\n",
    ")\n",
    "ax.set_title(\"Hurricane Season 2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were going to iterate over both, the selected storms and the selected drifters. For each of the trajectories, we plot their starting point and store some data to be utilized for generating the animation.\n",
    "\n",
    "Lets unpack the data variables from a ragged array (1-d array composed of each rows data variable segment) into a list of row data variable segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clouddrift.ragged import unpack\n",
    "\n",
    "storm_indices = np.array(range(len(matching_storms.id)))\n",
    "drifter_indices = np.array(range(len(matching_drifters.id)))\n",
    "\n",
    "storm_lons = unpack(matching_storms.lon, matching_storms.rowsize, storm_indices)\n",
    "storm_lats = unpack(matching_storms.lat, matching_storms.rowsize, storm_indices)\n",
    "\n",
    "drifter_lons = unpack(matching_drifters.lon, matching_drifters[\"rowsize\"], drifter_indices)\n",
    "drifter_lats = unpack(matching_drifters.lat, matching_drifters[\"rowsize\"], drifter_indices)\n",
    "drifter_temps = unpack(matching_drifters.temp, matching_drifters[\"rowsize\"], drifter_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the unpacked segments and plot the initial starting point of the storm and drifter trajectories (we also do some setup with setting up indexes to make searching later down the line easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_lines = list()\n",
    "drifter_lines = list()\n",
    "\n",
    "for storm_idx in storm_indices:\n",
    "    selected_lon, selected_lat = storm_lons[storm_idx], storm_lats[storm_idx]\n",
    "    selected_lon, selected_lat = selected_lon.set_xindex(\"time\"), selected_lat.set_xindex(\"time\")\n",
    "    line = ax.plot(selected_lon[0], selected_lat[0],\n",
    "        linestyle=\"-\", linewidth=3,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "    storm_lines.append((selected_lon, selected_lat, line[0]))\n",
    "\n",
    "for drifter_idx in drifter_indices:\n",
    "    selected_lon, selected_lat, selected_temp = drifter_lons[drifter_idx], drifter_lats[drifter_idx], drifter_temps[drifter_idx]\n",
    "    selected_lon, selected_lat, selected_temp = (selected_lon.set_xindex(\"time\"), selected_lat.set_xindex(\"time\"), selected_temp.set_xindex(\"time\"))\n",
    "    line = ax.plot(selected_lon[0], selected_lat[0],\n",
    "        linestyle=\"-\", linewidth=1,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "    drifter_lines.append((selected_lon, selected_lat, selected_temp, line[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now find the upper and lower bounds for the current temperature values being plotted. We'll use this to create a color map to color the drifter trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "min_t = np.nanmin([np.nanmin(temp) for (_, _, temp, _) in drifter_lines])\n",
    "max_t = np.nanmax([np.nanmax(temp) for (_, _, temp, _) in drifter_lines])\n",
    "\n",
    "cmap = plt.get_cmap(\"inferno\")\n",
    "norm = colors.Normalize(vmin=min_t, vmax=max_t)\n",
    "\n",
    "(min_t, max_t, cmap(norm(80)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add the legend for the color bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size=\"3%\", pad=0.75, axes_class=plt.Axes)\n",
    "fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax, label=\"temperature (K)\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the start and end date we've used for the criteria and generate an range of values that each map uniquely to a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frame_count = 500\n",
    "daterange = pd.date_range(start_dt, end_dt, frame_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now generate each frame by selecting the date associated to it which we utilize to update each trajectory with new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_frames = list()\n",
    "drifter_frames = list()\n",
    "frames = dict()\n",
    "tail_len = 20\n",
    "\n",
    "for idx, dt in enumerate(daterange):\n",
    "    if ((idx+1) % 100 == 0):\n",
    "        print(f\"generating index: {idx}\")\n",
    "\n",
    "    storm_updates = list()\n",
    "    for s_lon, s_lat, s_line in storm_lines:\n",
    "        sel_d_lon = s_lon.sel(time=slice(start_dt, dt))\n",
    "        sel_d_lat = s_lat.sel(time=slice(start_dt, dt))\n",
    "        storm_updates.append((sel_d_lon, sel_d_lat, s_line))\n",
    "\n",
    "    drifter_updates = list()\n",
    "    for d_lon, d_lat, d_temp, d_line, in drifter_lines:\n",
    "        sel_d_lon = d_lon.sel(time=slice(start_dt, dt))\n",
    "        sel_d_lat = d_lat.sel(time=slice(start_dt, dt))\n",
    "        sel_d_temp = d_temp.sel(time=slice(start_dt, dt))\n",
    "        sel_d_lon = sel_d_lon.tail(obs=tail_len)\n",
    "        sel_d_lat = sel_d_lat.tail(obs=tail_len)\n",
    "        sel_d_temp = sel_d_temp.tail(obs=tail_len)\n",
    "        drifter_updates.append((sel_d_lon, sel_d_lat, sel_d_temp, d_line))\n",
    "\n",
    "    frames[dt] = dict(drifter_updates=drifter_updates, storm_updates=storm_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an update function that, using the frame index, selects the frame and updates each trajectories longitude and latitude (and also temperature for the case of the drifters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_dates = sorted(frames.keys())\n",
    "\n",
    "def update(frame_idx):\n",
    "    frame_dt = sorted_dates[frame_idx]\n",
    "    frame = frames[frame_dt]\n",
    "    drifter_updates = frame[\"drifter_updates\"]\n",
    "    storm_updates = frame[\"storm_updates\"]\n",
    "\n",
    "    datetime_label.set_text(frame_dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    updated_lines = list()\n",
    "    for x_update, y_update, line in storm_updates:\n",
    "        line.set_xdata(x_update)\n",
    "        line.set_ydata(y_update)\n",
    "        updated_lines.append(line)\n",
    "\n",
    "    for x_update, y_update, temps, line in drifter_updates:\n",
    "        line.set_xdata(x_update)\n",
    "        line.set_ydata(y_update)\n",
    "        if len(temps) > 0:\n",
    "            line.set_color(cmap(norm(np.nanmean(temps))))\n",
    "        updated_lines.append(line)\n",
    "    return updated_lines\n",
    "\n",
    "ani = animation.FuncAnimation(fig=fig, func=update, frames=frame_count, interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate the animation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(\"storm_drifters.gif\", dpi=DPI, progress_callback=lambda i, n: print(f'Saving frame {i}/{n}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
